{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9DIbOcudXMk"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCHxlhDnbsZi",
    "outputId": "698f0a00-cff7-471b-ce8d-6cab42c8bdaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Extract precision, recall, and f1-score from classification report\n",
    "report = classification_report(Y_test, y_pred_labels, output_dict=True)\n",
    "for label, metrics in report.items():\n",
    "    if isinstance(metrics, dict):  # Only process label metrics, not summary stats\n",
    "        precision = metrics.get('precision', 0)\n",
    "        recall = metrics.get('recall', 0)\n",
    "        print(f'Label {label}: Precision = {precision:.2f}, Recall = {recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEDffeQreQyq"
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "nMKlKQJ_ePcl",
    "outputId": "6ec70122-5bd8-42cb-b4a6-b62d2e0fc25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  category\n",
      "0   family mormon have never tried explain them t...         1\n",
      "1  buddhism has very much lot compatible with chr...         1\n",
      "2  seriously don say thing first all they won get...        -1\n",
      "3  what you have learned yours and only yours wha...         0\n",
      "4  for your own benefit you may want read living ...         1\n",
      "\n",
      " (37249, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "text        100\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/content/Reddit_Data.csv\")\n",
    "\n",
    "print(data.head())\n",
    "print(\"\\n\",data.shape)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzergdvGffo0"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "aiSwC4m0fOul",
    "outputId": "c11c1f7c-b4b7-4f87-f7b5-2b178a15df16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[family, mormon, never, tried, explain, still,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[buddhism, much, lot, compatible, christianity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[seriously, say, thing, first, get, complex, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[learned, want, teach, different, focus, goal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[benefit, may, want, read, living, buddha, liv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0    [family, mormon, never, tried, explain, still,...\n",
       "1    [buddhism, much, lot, compatible, christianity...\n",
       "2    [seriously, say, thing, first, get, complex, e...\n",
       "3    [learned, want, teach, different, focus, goal,...\n",
       "4    [benefit, may, want, read, living, buddha, liv...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Applying function to dataset\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Tokenize\n",
    "data['tokens'] = data['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# Print\n",
    "data['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe_yLQfzg06e"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEy7Xf_Rgl3Q",
    "outputId": "f806dff5-856b-4b0e-9d5b-ef3d905fd42e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37249, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "\n",
    "# Fit and transform the text data\n",
    "X = vectorizer.fit_transform(data['cleaned_text'])\n",
    "Y = data['category']\n",
    "\n",
    "# Save\n",
    "pickle.dump(vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n",
    "\n",
    "# Print\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdDNbhL5h8Hu"
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZ_zUQ1chwV4",
    "outputId": "ba21fd18-2997-44d3-8bf2-624492046590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (29799, 5000) \n",
      "Test data shape: (7450, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Print\n",
    "print(f\"Training data shape: {X_train.shape} \\nTest data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNy58joQzepX"
   },
   "source": [
    "### Convert labels to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "rzZ4b-B-zRNw"
   },
   "outputs": [],
   "source": [
    "# Adjust labels for 3 classes: negative, neutral, positive\n",
    "Y_train_encoded = to_categorical(Y_train + 1, num_classes=3)\n",
    "Y_test_encoded = to_categorical(Y_test + 1, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mb07Qz1i2d9"
   },
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "hkfUnnk8iihk",
    "outputId": "0a194e25-34ab-4961-c158-bc5f83a506fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,280,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,539</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,539\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,539</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,539\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(tf.keras.layers.Dense(256, input_shape = (X_train.shape[1],), activation = 'relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# Compile\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Print\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0Z3AhdcukK6_"
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrices to dense\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou6MsOvCmgVo"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "xyd3srNgmdWz",
    "outputId": "9b08e6de-b8f7-43cb-9f37-0812f71e3f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.6322 - loss: 0.7917 - val_accuracy: 0.8442 - val_loss: 0.4388\n",
      "Epoch 2/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8901 - loss: 0.3266 - val_accuracy: 0.8510 - val_loss: 0.4303\n",
      "Epoch 3/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9351 - loss: 0.2161 - val_accuracy: 0.8510 - val_loss: 0.4585\n",
      "Epoch 4/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9535 - loss: 0.1572 - val_accuracy: 0.8428 - val_loss: 0.5227\n",
      "Epoch 5/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9680 - loss: 0.1133 - val_accuracy: 0.8448 - val_loss: 0.5775\n",
      "Epoch 6/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9777 - loss: 0.0795 - val_accuracy: 0.8420 - val_loss: 0.6658\n",
      "Epoch 7/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.0652 - val_accuracy: 0.8412 - val_loss: 0.7260\n",
      "Epoch 8/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.9851 - loss: 0.0531 - val_accuracy: 0.8392 - val_loss: 0.7355\n",
      "Epoch 9/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.9867 - loss: 0.0503 - val_accuracy: 0.8411 - val_loss: 0.8072\n",
      "Epoch 10/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.9878 - loss: 0.0419 - val_accuracy: 0.8379 - val_loss: 0.8286\n",
      "Epoch 11/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9895 - loss: 0.0352 - val_accuracy: 0.8346 - val_loss: 0.9102\n",
      "Epoch 12/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9899 - loss: 0.0338 - val_accuracy: 0.8396 - val_loss: 0.9717\n",
      "Epoch 13/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9924 - loss: 0.0295 - val_accuracy: 0.8373 - val_loss: 0.9708\n",
      "Epoch 14/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9921 - loss: 0.0304 - val_accuracy: 0.8361 - val_loss: 1.0148\n",
      "Epoch 15/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9915 - loss: 0.0304 - val_accuracy: 0.8383 - val_loss: 1.1026\n",
      "Epoch 16/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8349 - val_loss: 1.0695\n",
      "Epoch 17/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - accuracy: 0.9927 - loss: 0.0250 - val_accuracy: 0.8360 - val_loss: 1.0986\n",
      "Epoch 18/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.9926 - loss: 0.0260 - val_accuracy: 0.8401 - val_loss: 1.1449\n",
      "Epoch 19/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.9931 - loss: 0.0233 - val_accuracy: 0.8364 - val_loss: 1.1736\n",
      "Epoch 20/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9927 - loss: 0.0241 - val_accuracy: 0.8395 - val_loss: 1.1933\n",
      "Epoch 21/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.9940 - loss: 0.0214 - val_accuracy: 0.8334 - val_loss: 1.2297\n",
      "Epoch 22/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9927 - loss: 0.0252 - val_accuracy: 0.8376 - val_loss: 1.1990\n",
      "Epoch 23/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9939 - loss: 0.0227 - val_accuracy: 0.8369 - val_loss: 1.2389\n",
      "Epoch 24/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - accuracy: 0.9938 - loss: 0.0236 - val_accuracy: 0.8393 - val_loss: 1.2414\n",
      "Epoch 25/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9936 - loss: 0.0249 - val_accuracy: 0.8383 - val_loss: 1.3034\n",
      "Epoch 26/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9928 - loss: 0.0262 - val_accuracy: 0.8368 - val_loss: 1.3230\n",
      "Epoch 27/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9930 - loss: 0.0258 - val_accuracy: 0.8360 - val_loss: 1.3188\n",
      "Epoch 28/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0225 - val_accuracy: 0.8387 - val_loss: 1.3169\n",
      "Epoch 29/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0191 - val_accuracy: 0.8417 - val_loss: 1.3132\n",
      "Epoch 30/30\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0210 - val_accuracy: 0.8391 - val_loss: 1.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_dense, Y_train_encoded, epochs = 30, batch_size = 32, validation_data = (X_test_dense, Y_test_encoded), verbose =1)\n",
    "\n",
    "# Save\n",
    "model.save('sentiment_analysis.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nAwNgS-rlTs"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3POpeSTm-CU",
    "outputId": "ebe3c1d4-f51f-4c73-822d-ba65b4b62cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8441 - loss: 1.2633\n",
      "Test Accuracy: 83.91%\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.72      0.74      1667\n",
      "           0       0.86      0.90      0.88      2615\n",
      "           1       0.86      0.85      0.85      3168\n",
      "\n",
      "    accuracy                           0.84      7450\n",
      "   macro avg       0.83      0.82      0.83      7450\n",
      "weighted avg       0.84      0.84      0.84      7450\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1208  165  294]\n",
      " [ 111 2357  147]\n",
      " [ 260  222 2686]]\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "loss, accuracy = model.evaluate(X_test_dense, Y_test_encoded)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "Y_pred = model.predict(X_test_dense)\n",
    "y_pred_labels = np.argmax(Y_pred, axis=1) - 1\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_pred_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred_labels))\n",
    "\n",
    "# Extract precision, recall, and f1-score from classification report\n",
    "report = classification_report(Y_test, y_pred_labels, output_dict=True)\n",
    "for label, metrics in report.items():\n",
    "    if isinstance(metrics, dict):  # Only process label metrics, not summary stats\n",
    "        precision = metrics.get('precision', 0)\n",
    "        recall = metrics.get('recall', 0)\n",
    "        print(f'Label {label}: Precision = {precision:.2f}, Recall = {recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-oA-XG3hsrDC"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "# Clean the input text using the previously defined clean_text function\n",
    "  cleaned_text = clean_text(text)\n",
    "\n",
    "  # Transform the cleaned text using the vectorizer\n",
    "  vectorized_text = vectorizer.transform([cleaned_text]).toarray()\n",
    "\n",
    "  # Predict sentiment\n",
    "  prediction = model.predict(vectorized_text)\n",
    "  sentiment_class = np.argmax(prediction)  # Get the predicted class (0, 1, 2)\n",
    "\n",
    "  # Map the sentiment class to labels\n",
    "  sentiment_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "  return sentiment_mapping[sentiment_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaDIS0cKtRw1",
    "outputId": "704c3b0c-79ff-499e-8937-dc659a3e2ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Text: Good\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Text: Fine\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Text: Moderate\n",
      "Predicted Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test examples\n",
    "examples = [\n",
    "    \"Good\",\n",
    "    \"Fine\",\n",
    "    \"Moderate\"\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    sentiment = predict_sentiment(example)\n",
    "    print(f\"Text: {example}\\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_4Z7Syv7-Vl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
